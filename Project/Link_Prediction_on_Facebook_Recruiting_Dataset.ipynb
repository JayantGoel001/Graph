{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayantGoel001/Graph/blob/master/Project/Link_Prediction_on_Facebook_Recruiting_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rOVNuiWHrnA",
        "outputId": "2a4e5a58-6a86-4c0a-da8a-c5e003b79bea"
      },
      "id": "7rOVNuiWHrnA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/train.csv .\n",
        "!cp drive/MyDrive/test.csv ."
      ],
      "metadata": {
        "id": "3M5zS0awHrAB"
      },
      "id": "3M5zS0awHrAB",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cc185138",
      "metadata": {
        "id": "cc185138"
      },
      "outputs": [],
      "source": [
        "# For creating graph \n",
        "import networkx as nx\n",
        "\n",
        "# NumPy for numerical computing\n",
        "import numpy as np\n",
        "\n",
        "# Pandas for DataFrames\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib for visualization\n",
        "from matplotlib import pyplot as plt\n",
        "# display plots in the notebook\n",
        "%matplotlib inline\n",
        "# import color maps\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Seaborn for easier visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Function for splitting training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tracking the time model takes\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f65d7630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "f65d7630",
        "outputId": "16a7b6dc-2f7f-45c8-fca5-d40c9a0e3db9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_node</th>\n",
              "      <th>destination_node</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>690569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>315892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>189226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>834328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1615927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>1194519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>470294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>961886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>626040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>176995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_node  destination_node\n",
              "0            1            690569\n",
              "1            1            315892\n",
              "2            1            189226\n",
              "3            2            834328\n",
              "4            2           1615927\n",
              "5            2           1194519\n",
              "6            2            470294\n",
              "7            2            961886\n",
              "8            2            626040\n",
              "9            3            176995"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df=pd.read_csv('train.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9b13a7c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "9b13a7c3",
        "outputId": "01ca924d-cfeb-43d9-a252-7177e866b84d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_node</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_node\n",
              "0           20\n",
              "1           24\n",
              "2           31\n",
              "3           35\n",
              "4           42\n",
              "5           49\n",
              "6           52\n",
              "7           62\n",
              "8           71\n",
              "9           74"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df1=pd.read_csv('test.csv')\n",
        "df1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2a3fa8c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2a3fa8c4",
        "outputId": "dd7469be-8f7a-4584-f46f-c397a2ca6bb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_node</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_node\n",
              "0           20\n",
              "1           24\n",
              "2           31\n",
              "3           35\n",
              "4           42"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "35a52e17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35a52e17",
        "outputId": "f5b5e640-158a-443b-8496-ebe4301b532c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9437519, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e89fc8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2e89fc8c",
        "outputId": "fb387eb8-72e2-4e6f-e84d-31f2d7c086a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_node</th>\n",
              "      <th>destination_node</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>690569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>315892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>189226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>834328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1615927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_node  destination_node\n",
              "0            1            690569\n",
              "1            1            315892\n",
              "2            1            189226\n",
              "3            2            834328\n",
              "4            2           1615927"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ff231828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff231828",
        "outputId": "ec210fd6-8ea7-42c7-a266-c918aa6ede3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sum(df.isna().any(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6cf1a3ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cf1a3ce",
        "outputId": "1f29c712-9d76-4343-9b64-48147f310e6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sum(df.duplicated())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b055cdf",
      "metadata": {
        "id": "5b055cdf"
      },
      "source": [
        "# Saving csv without header "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xANx5o8zIBPy",
        "outputId": "4e0e64b8-d7a7-438b-f977-a164cfb2f673"
      },
      "id": "xANx5o8zIBPy",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1fafd895",
      "metadata": {
        "id": "1fafd895"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data/train_woheader.csv',header=False,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179b15aa",
      "metadata": {
        "id": "179b15aa"
      },
      "outputs": [],
      "source": [
        "g=nx.read_edgelist('data/train_woheader.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a230d61",
      "metadata": {
        "id": "2a230d61"
      },
      "source": [
        "** Observation **\n",
        " * This graph is directed graph.\n",
        " * nx() is by defalut undirected graph."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1cddca8",
      "metadata": {
        "id": "a1cddca8"
      },
      "source": [
        "### Basic Information of graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7403fa01",
      "metadata": {
        "id": "7403fa01"
      },
      "outputs": [],
      "source": [
        "print(nx.info(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8d7cfe",
      "metadata": {
        "id": "0e8d7cfe"
      },
      "source": [
        "* in degree = incoming node.\n",
        "* out degree = outgoing node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95aabf42",
      "metadata": {
        "id": "95aabf42"
      },
      "source": [
        "# Reading 50 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e64498",
      "metadata": {
        "id": "66e64498"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('train.csv',nrows=50).to_csv('data/train_woheader_sample.csv',header=False,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bc4ad8",
      "metadata": {
        "id": "37bc4ad8"
      },
      "outputs": [],
      "source": [
        "subgraph=nx.read_edgelist('data/train_woheader_sample.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e260f5a7",
      "metadata": {
        "id": "e260f5a7"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cde16bf",
      "metadata": {
        "id": "0cde16bf"
      },
      "outputs": [],
      "source": [
        "pos=nx.spring_layout(subgraph) # spring = circle layout\n",
        "nx.draw(subgraph,pos,node_color='#A0CBE2',edge_color='#00bb5e',width=1,edge_cmap=plt.cm.Blues,with_labels=True)\n",
        "plt.savefig(\"graph_sample.pdf\")\n",
        "print(nx.info(subgraph))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a06e698",
      "metadata": {
        "id": "7a06e698"
      },
      "source": [
        "* inner nodes are source nodes and outer nodes are destination nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5b7747",
      "metadata": {
        "id": "dd5b7747"
      },
      "outputs": [],
      "source": [
        "#No. of unique nodes\n",
        "len(g.nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d535ffea",
      "metadata": {
        "id": "d535ffea"
      },
      "outputs": [],
      "source": [
        "indegree_dist = list(dict(g.in_degree()).values())\n",
        "indegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(indegree_dist)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of Followers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdf266fb",
      "metadata": {
        "id": "cdf266fb"
      },
      "source": [
        "** Observation **\n",
        "* There are very less people having more followers. i.e. we have the data of common peoples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3781eb4",
      "metadata": {
        "id": "f3781eb4"
      },
      "outputs": [],
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(indegree_dist,90+i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1039e682",
      "metadata": {
        "id": "1039e682"
      },
      "outputs": [],
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(indegree_dist,99+(i/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab58af2a",
      "metadata": {
        "id": "ab58af2a"
      },
      "outputs": [],
      "source": [
        "outdegree_dist = list(dict(g.out_degree()).values())\n",
        "outdegree_dist.sort()\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(outdegree_dist)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of Followee')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e882d2",
      "metadata": {
        "id": "b2e882d2"
      },
      "source": [
        "** Observation **\n",
        "* There are very less people having more followee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af238adc",
      "metadata": {
        "id": "af238adc"
      },
      "outputs": [],
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(outdegree_dist,90+i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b213240a",
      "metadata": {
        "id": "b213240a"
      },
      "outputs": [],
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(outdegree_dist,99+(i/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ab7687",
      "metadata": {
        "id": "96ab7687"
      },
      "outputs": [],
      "source": [
        "print('No of persons those are not following anyone are' ,sum(np.array(outdegree_dist)==0),'and % is',\n",
        "        sum(np.array(outdegree_dist)==0)*100/len(outdegree_dist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c18d3c",
      "metadata": {
        "id": "46c18d3c"
      },
      "outputs": [],
      "source": [
        "print('No of persons who have no followers' ,sum(np.array(indegree_dist)==0),'and % is',\n",
        "        sum(np.array(indegree_dist)==0)*100/len(indegree_dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b18647",
      "metadata": {
        "id": "c3b18647"
      },
      "source": [
        "** Observation **\n",
        "* The above data indicates that these many people are not using or not active on social n/w "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d744d3",
      "metadata": {
        "id": "b5d744d3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "dict_in = dict(g.in_degree())\n",
        "dict_out = dict(g.out_degree())\n",
        "d = Counter(dict_in) + Counter(dict_out)\n",
        "in_out_degree = np.array(list(d.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9620ae9",
      "metadata": {
        "id": "a9620ae9"
      },
      "outputs": [],
      "source": [
        "in_out_degree_sort = sorted(in_out_degree)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(in_out_degree_sort)\n",
        "plt.xlabel('Index No')\n",
        "plt.ylabel('No Of people each person is following + followers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df11385e",
      "metadata": {
        "id": "df11385e"
      },
      "outputs": [],
      "source": [
        "### 90-100 percentile\n",
        "for i in range(0,11):\n",
        "    print(90+i,'percentile value is',np.percentile(in_out_degree_sort,90+i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb53cea",
      "metadata": {
        "id": "beb53cea"
      },
      "outputs": [],
      "source": [
        "### 99-100 percentile\n",
        "for i in range(10,110,10):\n",
        "    print(99+(i/100),'percentile value is',np.percentile(in_out_degree_sort,99+(i/100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4887809b",
      "metadata": {
        "id": "4887809b"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba8e2f1",
      "metadata": {
        "id": "fba8e2f1"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657cb411",
      "metadata": {
        "id": "657cb411"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "###generating missing edges from given graph\n",
        "import random\n",
        "#getting all set of edges\n",
        "r = csv.reader(open('data/train_woheader.csv','r'))\n",
        "#the dict will contain a tuple of 2 nodes as key and the value will be 1 is the nodes are connected else -1\n",
        "edges = dict()\n",
        "# for present edges.\n",
        "for edge in r: # i.e. edge is present in train data.\n",
        "\tedges[(edge[0], edge[1])] = 1 # if edge is present in r then 1.\n",
        "\n",
        "# for missing edges.\n",
        "missing_edges = set([])\n",
        "while (len(missing_edges)<9437519):\n",
        "\ta=random.randint(1, 1862220) # no. of nodes\n",
        "\tb=random.randint(1, 1862220) # no. of nodes\n",
        "\ttmp = edges.get((a,b),-1) # marked -1 for all edges which are missing.\n",
        "\tif tmp == -1 and a!=b: # if edge is missing and a and b are not same.\n",
        "\t\ttry:\n",
        "            # adding points who less likely to be friends\n",
        "\t\t\tif nx.shortest_path_length(g,source=a,target=b) > 2: # greater than 2 coz more dist. low prob. to become a frd. That is what we want as a data/edge to add or join.\n",
        "\n",
        "\t\t\t\tmissing_edges.add((a,b))\n",
        "\t\t\telse:\n",
        "\t\t\t\tcontinue  \n",
        "\t\texcept:  \n",
        "\t\t\t\tmissing_edges.add((a,b))              \n",
        "\telse:\n",
        "\t\tcontinue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abccec4b",
      "metadata": {
        "id": "abccec4b"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875be8f4",
      "metadata": {
        "id": "875be8f4"
      },
      "source": [
        "Saving the pickle file of missing_edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ca83ca",
      "metadata": {
        "id": "14ca83ca"
      },
      "outputs": [],
      "source": [
        "pickle.dump(missing_edges,open('data/missing_edges_final.p','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e865544",
      "metadata": {
        "id": "3e865544"
      },
      "outputs": [],
      "source": [
        "len(missing_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40982649",
      "metadata": {
        "id": "40982649"
      },
      "source": [
        "* positive = connected nodes\n",
        "* negative = missing nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfab004a",
      "metadata": {
        "id": "dfab004a"
      },
      "outputs": [],
      "source": [
        "file = open(\"data/missing_edges_final.p\",\"rb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec9caed",
      "metadata": {
        "id": "eec9caed"
      },
      "outputs": [],
      "source": [
        "missing_edges = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070a7566",
      "metadata": {
        "id": "070a7566"
      },
      "outputs": [],
      "source": [
        "#reading total data df\n",
        "df_pos = pd.read_csv('train.csv')\n",
        "df_neg = pd.DataFrame(list(missing_edges), columns=['source_node', 'destination_node'])\n",
        "\n",
        "print(\"Number of nodes in the graph with edges\", df_pos.shape[0])\n",
        "print(\"Number of nodes in the graph without edges\", df_neg.shape[0])\n",
        "\n",
        "#Trian test split \n",
        "#Spiltted data into 80-20 \n",
        "#positive links and negative links seperatly because we need positive training data only for creating graph \n",
        "#and for feature generation\n",
        "X_train_pos, X_test_pos, y_train_pos, y_test_pos  = train_test_split(df_pos,np.ones(len(df_pos)),test_size=0.2, random_state=9)\n",
        "X_train_neg, X_test_neg, y_train_neg, y_test_neg  = train_test_split(df_neg,np.zeros(len(df_neg)),test_size=0.2, random_state=9)\n",
        "\n",
        "print('='*60)\n",
        "print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0],\"=\",y_train_pos.shape[0])\n",
        "print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0],\"=\", y_train_neg.shape[0])\n",
        "print('='*60)\n",
        "print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0],\"=\",y_test_pos.shape[0])\n",
        "print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0],\"=\",y_test_neg.shape[0])\n",
        "\n",
        "#removing header and saving\n",
        "X_train_pos.to_csv('data/train_pos_after_eda.csv',header=False, index=False)\n",
        "X_test_pos.to_csv('data/test_pos_after_eda.csv',header=False, index=False)\n",
        "X_train_neg.to_csv('data/train_neg_after_eda.csv',header=False, index=False)\n",
        "X_test_neg.to_csv('data/test_neg_after_eda.csv',header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b13751",
      "metadata": {
        "id": "f4b13751"
      },
      "outputs": [],
      "source": [
        "X_train_pos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edbafabc",
      "metadata": {
        "id": "edbafabc"
      },
      "outputs": [],
      "source": [
        "X_test_pos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7313a945",
      "metadata": {
        "id": "7313a945"
      },
      "outputs": [],
      "source": [
        "y_train_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792f7e9f",
      "metadata": {
        "id": "792f7e9f"
      },
      "outputs": [],
      "source": [
        "y_test_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fddf723",
      "metadata": {
        "id": "3fddf723"
      },
      "outputs": [],
      "source": [
        "del missing_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e89a8ae",
      "metadata": {
        "id": "7e89a8ae"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57409cb9",
      "metadata": {
        "id": "57409cb9"
      },
      "outputs": [],
      "source": [
        "if (os.path.isfile('data/train_pos_after_eda.csv')) and (os.path.isfile('data/test_pos_after_eda.csv')):        \n",
        "    train_graph=nx.read_edgelist('data/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    test_graph=nx.read_edgelist('data/test_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "    print(nx.info(train_graph))\n",
        "    print(nx.info(test_graph))\n",
        "\n",
        "    # finding the unique nodes in the both train and test graphs\n",
        "    train_nodes_pos = set(train_graph.nodes())\n",
        "    test_nodes_pos = set(test_graph.nodes())\n",
        "\n",
        "    trY_teY = len(train_nodes_pos.intersection(test_nodes_pos))\n",
        "    trY_teN = len(train_nodes_pos - test_nodes_pos)\n",
        "    teY_trN = len(test_nodes_pos - train_nodes_pos)\n",
        "\n",
        "    print('no of people common in train and test -- ',trY_teY)\n",
        "    print('no of people present in train but not present in test -- ',trY_teN)\n",
        "\n",
        "    print('no of people present in test but not present in train -- ',teY_trN)\n",
        "    print(' % of people not there in Train but exist in Test in total Test data are {} %'.format(teY_trN/len(test_nodes_pos)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbb9bda",
      "metadata": {
        "id": "efbb9bda"
      },
      "outputs": [],
      "source": [
        "#final train and test data sets\n",
        "if (not os.path.isfile('data/train_after_eda.csv')) and \\\n",
        "(not os.path.isfile('data/test_after_eda.csv')) and \\\n",
        "(not os.path.isfile('data/train_y.csv')) and \\\n",
        "(not os.path.isfile('data/test_y.csv')) and \\\n",
        "(os.path.isfile('data/train_pos_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/test_pos_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/train_neg_after_eda.csv')) and \\\n",
        "(os.path.isfile('data/test_neg_after_eda.csv')):\n",
        "    \n",
        "    X_train_pos = pd.read_csv('data/train_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_test_pos = pd.read_csv('data/test_pos_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_train_neg = pd.read_csv('data/train_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "    X_test_neg = pd.read_csv('data/test_neg_after_eda.csv', names=['source_node', 'destination_node'])\n",
        "\n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the train data graph with edges\", X_train_pos.shape[0])\n",
        "    print(\"Number of nodes in the train data graph without edges\", X_train_neg.shape[0])\n",
        "    print('='*60)\n",
        "    print(\"Number of nodes in the test data graph with edges\", X_test_pos.shape[0])\n",
        "    print(\"Number of nodes in the test data graph without edges\", X_test_neg.shape[0])\n",
        "\n",
        "    X_train = X_train_pos.append(X_train_neg,ignore_index=True)\n",
        "    y_train = np.concatenate((y_train_pos,y_train_neg))\n",
        "    X_test = X_test_pos.append(X_test_neg,ignore_index=True)\n",
        "    y_test = np.concatenate((y_test_pos,y_test_neg)) \n",
        "    \n",
        "    X_train.to_csv('data/train_after_eda.csv',header=False,index=False)\n",
        "    X_test.to_csv('data/test_after_eda.csv',header=False,index=False)\n",
        "    pd.DataFrame(y_train.astype(int)).to_csv('data/train_y.csv',header=False,index=False)\n",
        "    pd.DataFrame(y_test.astype(int)).to_csv('data/test_y.csv',header=False,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa71915e",
      "metadata": {
        "id": "fa71915e"
      },
      "outputs": [],
      "source": [
        "print(\"Data points in train data\",X_train.shape)\n",
        "print(\"Data points in test data\",X_test.shape)\n",
        "print(\"Shape of traget variable in train\",y_train.shape)\n",
        "print(\"Shape of traget variable in test\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fffa49f7",
      "metadata": {
        "id": "fffa49f7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae69ac7",
      "metadata": {
        "id": "5ae69ac7"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "import csv\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from pandas import HDFStore,DataFrame\n",
        "from pandas import read_hdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e35c092",
      "metadata": {
        "id": "1e35c092"
      },
      "source": [
        "Reading only the train positive (present edges) file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cec2da6",
      "metadata": {
        "id": "7cec2da6"
      },
      "outputs": [],
      "source": [
        "train_graph=nx.read_edgelist('data/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
        "print(nx.info(train_graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add3981b",
      "metadata": {
        "id": "add3981b"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597fe1f2",
      "metadata": {
        "id": "597fe1f2"
      },
      "source": [
        "1.Jaccard distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6240f545",
      "metadata": {
        "id": "6240f545"
      },
      "outputs": [],
      "source": [
        "#for followees\n",
        "def jaccard_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
        "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
        "    except:\n",
        "        return 0\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b6c258",
      "metadata": {
        "id": "a6b6c258"
      },
      "outputs": [],
      "source": [
        "#for followers\n",
        "def jaccard_for_followers(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
        "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e08deb",
      "metadata": {
        "id": "33e08deb"
      },
      "source": [
        "\\begin{equation}\n",
        "CosineDistance = \\frac{|X\\cap Y|}{SQRT(|X|\\cdot|Y|)} \n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2aa20f6",
      "metadata": {
        "id": "a2aa20f6"
      },
      "source": [
        "2.Cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "313fe829",
      "metadata": {
        "id": "313fe829"
      },
      "outputs": [],
      "source": [
        "#for followees\n",
        "def cosine_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
        "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4076cc72",
      "metadata": {
        "id": "4076cc72"
      },
      "outputs": [],
      "source": [
        "def cosine_for_followers(a,b):\n",
        "    try:\n",
        "        \n",
        "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
        "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a2097d",
      "metadata": {
        "id": "b0a2097d"
      },
      "source": [
        "3.page rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb3d62b",
      "metadata": {
        "id": "2bb3d62b"
      },
      "outputs": [],
      "source": [
        "pr = nx.pagerank(train_graph, alpha=0.85)\n",
        "pickle.dump(pr,open('data/page_rank.p','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7cc948",
      "metadata": {
        "id": "ec7cc948"
      },
      "outputs": [],
      "source": [
        "mean_pr=float(sum(pr.values())) / len(pr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f456221b",
      "metadata": {
        "id": "f456221b"
      },
      "outputs": [],
      "source": [
        "print('min',pr[min(pr, key=pr.get)])\n",
        "print('max',pr[max(pr, key=pr.get)])\n",
        "print('mean',float(sum(pr.values())) / len(pr))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105e77b1",
      "metadata": {
        "id": "105e77b1"
      },
      "source": [
        "For all the data points which are part of the test dataset but are not in the training dataset we will not have the pagerank for these data points.For these data points we will use the mean pagerank as imputation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea5a1d3",
      "metadata": {
        "id": "5ea5a1d3"
      },
      "source": [
        "4.shortest path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78d88f01",
      "metadata": {
        "id": "78d88f01"
      },
      "outputs": [],
      "source": [
        "#if has direct edge then deleting that edge and calculating shortest path\n",
        "def compute_shortest_path_length(a,b):\n",
        "    p=-1\n",
        "    try:\n",
        "        if train_graph.has_edge(a,b):\n",
        "            train_graph.remove_edge(a,b)\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "            train_graph.add_edge(a,b)\n",
        "        else:\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "        return p\n",
        "    except:\n",
        "        return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167c04da",
      "metadata": {
        "id": "167c04da"
      },
      "source": [
        "5.connected components\n",
        "Example of strongly connected components:In a particular component, there is atleast one path from any given node to any other node.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Strongly_connected_component#/media/File:Scc.png\n",
        "\n",
        "Every strongly connected component is a weakly connected component.However, if it is not a strongly connected component, then to check whether it is a weakly connected component remove the directions of the edges and see if still there is atleast one path from any given node to any other node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eae4c0e",
      "metadata": {
        "id": "0eae4c0e"
      },
      "source": [
        "5.Weakly connected components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a25e449",
      "metadata": {
        "id": "6a25e449"
      },
      "outputs": [],
      "source": [
        "#getting weekly connected edges from graph \n",
        "wcc=list(nx.weakly_connected_components(train_graph))\n",
        "def belongs_to_same_wcc(a,b):\n",
        "    index = []\n",
        "    if train_graph.has_edge(b,a):\n",
        "        return 1\n",
        "    if train_graph.has_edge(a,b):\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if (b in index):\n",
        "                train_graph.remove_edge(a,b)\n",
        "                if compute_shortest_path_length(a,b)==-1:\n",
        "                    train_graph.add_edge(a,b)\n",
        "                    return 0\n",
        "                else:\n",
        "                    train_graph.add_edge(a,b)\n",
        "                    return 1\n",
        "            else:\n",
        "                return 0\n",
        "    else:\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if(b in index):\n",
        "                return 1\n",
        "            else:\n",
        "                return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1360da45",
      "metadata": {
        "id": "1360da45"
      },
      "source": [
        "6.Adar Index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141c5ef7",
      "metadata": {
        "id": "141c5ef7"
      },
      "source": [
        "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices.\n",
        "$$A(x,y)=\\sum_{u \\in N(x) \\cap N(y)}\\frac{1}{log(|N(u)|)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72cd95a3",
      "metadata": {
        "id": "72cd95a3"
      },
      "outputs": [],
      "source": [
        "#adar index\n",
        "def calc_adar_in(a,b):\n",
        "    sum=0\n",
        "    try:\n",
        "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
        "        if len(n)!=0:\n",
        "            for i in n:\n",
        "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
        "            return sum\n",
        "        else:\n",
        "            return 0\n",
        "    except:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871a7d6c",
      "metadata": {
        "id": "871a7d6c"
      },
      "source": [
        "7.Follow Back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f88c159",
      "metadata": {
        "id": "5f88c159"
      },
      "outputs": [],
      "source": [
        "def follows_back(a,b):\n",
        "    if train_graph.has_edge(b,a):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30addaf2",
      "metadata": {
        "id": "30addaf2"
      },
      "source": [
        "8.Katz Centrality\n",
        "\n",
        "https://www.geeksforgeeks.org/katz-centrality-centrality-measure/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ab2c44",
      "metadata": {
        "id": "12ab2c44"
      },
      "outputs": [],
      "source": [
        "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
        "pickle.dump(katz,open('data/fea_sample/katz.p','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c29e6c",
      "metadata": {
        "id": "b9c29e6c"
      },
      "outputs": [],
      "source": [
        "mean_katz=float(sum(katz.values())) / len(katz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113c0374",
      "metadata": {
        "id": "113c0374"
      },
      "outputs": [],
      "source": [
        "print('min',katz[min(katz, key=katz.get)])\n",
        "print('max',katz[max(katz, key=katz.get)])\n",
        "print('mean',float(sum(katz.values())) / len(katz))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5442b2d",
      "metadata": {
        "id": "b5442b2d"
      },
      "source": [
        "9.HITS\n",
        "\n",
        "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links.\n",
        "\n",
        "https://en.wikipedia.org/wiki/HITS_algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405c2f38",
      "metadata": {
        "id": "405c2f38"
      },
      "outputs": [],
      "source": [
        "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
        "pickle.dump(hits,open('data/fea_sample/hits.p','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d561d14",
      "metadata": {
        "id": "7d561d14"
      },
      "outputs": [],
      "source": [
        "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
        "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
        "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf5fd8f",
      "metadata": {
        "id": "ebf5fd8f"
      },
      "source": [
        "Sampling the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a0094c",
      "metadata": {
        "id": "e6a0094c"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee6c64a",
      "metadata": {
        "id": "6ee6c64a"
      },
      "outputs": [],
      "source": [
        "filename = \"data/train_after_eda.csv\"\n",
        "n_train = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
        "s = 100000 #desired sample size\n",
        "skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071fef94",
      "metadata": {
        "id": "071fef94"
      },
      "outputs": [],
      "source": [
        "filename = \"data/test_after_eda.csv\"\n",
        "n_test = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
        "s = 50000 #desired sample size\n",
        "skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9363366",
      "metadata": {
        "id": "c9363366"
      },
      "outputs": [],
      "source": [
        "print(\"Number of rows in the train data file:\", n_train)\n",
        "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
        "print(\"Number of rows in the test data file:\", n_test)\n",
        "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35a3dc2",
      "metadata": {
        "id": "c35a3dc2"
      },
      "outputs": [],
      "source": [
        "df_final_train = pd.read_csv('data/train_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
        "df_final_train['indicator_link'] = pd.read_csv('data/train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
        "print(\"Our train matrix size \",df_final_train.shape)\n",
        "df_final_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df541a6b",
      "metadata": {
        "id": "df541a6b"
      },
      "outputs": [],
      "source": [
        "df_final_test = pd.read_csv('data/test_after_eda.csv', skiprows=skip_test, names=['source_node', 'destination_node'])\n",
        "df_final_test['indicator_link'] = pd.read_csv('data/test_y.csv', skiprows=skip_test, names=['indicator_link'])\n",
        "print(\"Our test matrix size \",df_final_test.shape)\n",
        "df_final_test.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b966978",
      "metadata": {
        "id": "6b966978"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "#mapping jaccrd followers to train and test data\n",
        "df_final_train['jaccard_followers'] = df_final_train.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tjaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "df_final_test['jaccard_followers'] = df_final_test.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tjaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#mapping jaccrd followees to train and test data\n",
        "df_final_train['jaccard_followees'] = df_final_train.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tjaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "df_final_test['jaccard_followees'] = df_final_test.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tjaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "\n",
        "\t#mapping jaccrd followers to train and test data\n",
        "df_final_train['cosine_followers'] = df_final_train.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tcosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "df_final_test['cosine_followers'] = df_final_test.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tcosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#mapping jaccrd followees to train and test data\n",
        "df_final_train['cosine_followees'] = df_final_train.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tcosine_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "df_final_test['cosine_followees'] = df_final_test.apply(lambda row:\n",
        "\t\t\t\t\t\t\t\t\t\tcosine_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542c43ea",
      "metadata": {
        "id": "542c43ea"
      },
      "outputs": [],
      "source": [
        "def compute_features_stage1(df_final):\n",
        "    #calculating no of followers followees for source and destination\n",
        "    #calculating intersection of followers and followees for source and destination\n",
        "    num_followers_s=[]\n",
        "    num_followees_s=[]\n",
        "    num_followers_d=[]\n",
        "    num_followees_d=[]\n",
        "    inter_followers=[]\n",
        "    inter_followees=[]\n",
        "    for i,row in df_final.iterrows():\n",
        "        try:\n",
        "            s1=set(train_graph.predecessors(row['source_node']))\n",
        "            s2=set(train_graph.successors(row['source_node']))\n",
        "        except:\n",
        "            s1 = set()\n",
        "            s2 = set()\n",
        "        try:\n",
        "            d1=set(train_graph.predecessors(row['destination_node']))\n",
        "            d2=set(train_graph.successors(row['destination_node']))\n",
        "        except:\n",
        "            d1 = set()\n",
        "            d2 = set()\n",
        "        num_followers_s.append(len(s1))\n",
        "        num_followees_s.append(len(s2))\n",
        "\n",
        "        num_followers_d.append(len(d1))\n",
        "        num_followees_d.append(len(d2))\n",
        "\n",
        "        inter_followers.append(len(s1.intersection(d1)))\n",
        "        inter_followees.append(len(s2.intersection(d2)))\n",
        "    \n",
        "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7210666",
      "metadata": {
        "id": "c7210666"
      },
      "outputs": [],
      "source": [
        "df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
        "df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
        "df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8911f5",
      "metadata": {
        "id": "cf8911f5"
      },
      "outputs": [],
      "source": [
        "df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
        "df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
        "df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d974e14f",
      "metadata": {
        "id": "d974e14f"
      },
      "outputs": [],
      "source": [
        "hdf = HDFStore('data/fea_sample/storage_sample_stage1.h5')\n",
        "hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "hdf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218337db",
      "metadata": {
        "id": "218337db"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "#mapping adar index on train\n",
        "df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
        "#mapping adar index on test\n",
        "df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "#mapping followback or not on train\n",
        "df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#mapping followback or not on test\n",
        "df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "#mapping same component of wcc or not on train\n",
        "df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "##mapping same component of wcc or not on train\n",
        "df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "#mapping shortest path on train \n",
        "df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
        "#mapping shortest path on test\n",
        "df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
        "\n",
        "hdf = HDFStore('data/fea_sample/storage_sample_stage2.h5')\n",
        "hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "hdf.close()\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7090f6f4",
      "metadata": {
        "id": "7090f6f4"
      },
      "outputs": [],
      "source": [
        "file = open(\"data/page_rank1.p\",\"rb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bb5462",
      "metadata": {
        "id": "79bb5462"
      },
      "outputs": [],
      "source": [
        "pr = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebb09d7",
      "metadata": {
        "id": "aebb09d7"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "#page rank for source and destination in Train and Test\n",
        "#if anything not there in train graph then adding mean page rank \n",
        "df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "\n",
        "df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
        "#================================================================================\n",
        "\n",
        "#Katz centrality score for source and destination in Train and test\n",
        "#if anything not there in train graph then adding mean katz score\n",
        "df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "\n",
        "df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
        "#================================================================================\n",
        "\n",
        "#Hits algorithm score for source and destination in Train and test\n",
        "#if anything not there in train graph then adding 0\n",
        "df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
        "df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
        "\n",
        "df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
        "df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
        "#================================================================================\n",
        "\n",
        "#Hits algorithm score for source and destination in Train and Test\n",
        "#if anything not there in train graph then adding 0\n",
        "df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
        "df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
        "\n",
        "df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
        "df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))\n",
        "#================================================================================\n",
        "\n",
        "hdf = HDFStore('data/fea_sample/storage_sample_stage3.h5')\n",
        "hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
        "hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
        "hdf.close()\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3139d2",
      "metadata": {
        "id": "5f3139d2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518c0880",
      "metadata": {
        "id": "518c0880"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from time import time\n",
        "import csv\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from pandas import HDFStore,DataFrame\n",
        "from pandas import read_hdf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Libraries to perform hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance  ## to plot feature importance\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
        "\n",
        "# To save the final model on disk\n",
        "from sklearn.externals import joblib  ## Reference http://scikit-learn.org/stable/modules/model_persistence.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d82e39be",
      "metadata": {
        "id": "d82e39be"
      },
      "source": [
        "Making train n test data from h5 files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87e7493",
      "metadata": {
        "id": "a87e7493"
      },
      "outputs": [],
      "source": [
        "df_final_train = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'train_df',mode='r')\n",
        "df_final_test = read_hdf('data/fea_sample/storage_sample_stage3.h5', 'test_df',mode='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9d90d7",
      "metadata": {
        "id": "3a9d90d7"
      },
      "outputs": [],
      "source": [
        "df_final_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4664c417",
      "metadata": {
        "id": "4664c417"
      },
      "outputs": [],
      "source": [
        "df_final_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bea3777",
      "metadata": {
        "id": "1bea3777"
      },
      "outputs": [],
      "source": [
        "df_final_train.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3202e791",
      "metadata": {
        "id": "3202e791"
      },
      "source": [
        "Target data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a913ff",
      "metadata": {
        "id": "c4a913ff"
      },
      "outputs": [],
      "source": [
        "y_train = df_final_train.indicator_link\n",
        "y_test = df_final_test.indicator_link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec64ea52",
      "metadata": {
        "id": "ec64ea52"
      },
      "source": [
        "Droping unwanted columns and target var."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d8d781",
      "metadata": {
        "id": "82d8d781"
      },
      "outputs": [],
      "source": [
        "df_final_train.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)\n",
        "df_final_test.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb57cc57",
      "metadata": {
        "id": "eb57cc57"
      },
      "source": [
        "inefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c91cd93",
      "metadata": {
        "id": "5c91cd93"
      },
      "outputs": [],
      "source": [
        "estimators = [10,50,100,250,450]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "for i in estimators:\n",
        "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=52, min_samples_split=120,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=i, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
        "    clf.fit(df_final_train,y_train)\n",
        "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
        "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
        "    test_scores.append(test_sc)\n",
        "    train_scores.append(train_sc)\n",
        "    print('Estimators = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
        "plt.plot(estimators,train_scores,label='Train Score')\n",
        "plt.plot(estimators,test_scores,label='Test Score')\n",
        "plt.xlabel('Estimators')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Estimators vs score at depth of 5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33bd7fb3",
      "metadata": {
        "id": "33bd7fb3"
      },
      "source": [
        "inefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6fe69bb",
      "metadata": {
        "id": "b6fe69bb"
      },
      "outputs": [],
      "source": [
        "depths = [3,9,11,15,20,35,50,70,130]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "for i in depths:\n",
        "    clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=i, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=52, min_samples_split=120,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=115, n_jobs=-1,random_state=25,verbose=0,warm_start=False)\n",
        "    clf.fit(df_final_train,y_train)\n",
        "    train_sc = f1_score(y_train,clf.predict(df_final_train))\n",
        "    test_sc = f1_score(y_test,clf.predict(df_final_test))\n",
        "    test_scores.append(test_sc)\n",
        "    train_scores.append(train_sc)\n",
        "    print('depth = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
        "plt.plot(depths,train_scores,label='Train Score')\n",
        "plt.plot(depths,test_scores,label='Test Score')\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Depth vs score at depth of 5 at estimators = 115')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf009aa",
      "metadata": {
        "id": "5bf009aa"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db85f4f",
      "metadata": {
        "id": "8db85f4f"
      },
      "source": [
        "* df_final_train contain all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ac25bf",
      "metadata": {
        "id": "21ac25bf"
      },
      "outputs": [],
      "source": [
        "df_final_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af091faf",
      "metadata": {
        "id": "af091faf"
      },
      "source": [
        "* All the target variable of df_final_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f89f639",
      "metadata": {
        "id": "8f89f639"
      },
      "outputs": [],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d315148",
      "metadata": {
        "id": "2d315148"
      },
      "source": [
        "# Model : RandomForest Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd4b870",
      "metadata": {
        "id": "8fd4b870"
      },
      "outputs": [],
      "source": [
        "param_dist = {\"n_estimators\":sp_randint(105,125),\n",
        "              \"max_depth\": sp_randint(10,15),\n",
        "              \"min_samples_split\": sp_randint(110,190),\n",
        "              \"min_samples_leaf\": sp_randint(25,65)}\n",
        "\n",
        "clf = RandomForestClassifier(random_state=25,n_jobs=-1)\n",
        "\n",
        "rf_random = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=5,cv=10,scoring='f1',random_state=25)\n",
        "\n",
        "rf_random.fit(df_final_train,y_train)\n",
        "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
        "print('mean train scores',rf_random.cv_results_['mean_train_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c57c36e",
      "metadata": {
        "id": "3c57c36e"
      },
      "outputs": [],
      "source": [
        "print(rf_random.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ecb798",
      "metadata": {
        "id": "15ecb798"
      },
      "source": [
        "These are the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a434d54",
      "metadata": {
        "id": "5a434d54"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=28, min_samples_split=111,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=121, n_jobs=-1,\n",
        "            oob_score=False, random_state=25, verbose=0, warm_start=False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf237aa",
      "metadata": {
        "id": "fdf237aa"
      },
      "source": [
        "test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b735cd02",
      "metadata": {
        "id": "b735cd02"
      },
      "outputs": [],
      "source": [
        "clf.fit(df_final_train,y_train)\n",
        "y_train_pred = clf.predict(df_final_train)\n",
        "y_test_pred = clf.predict(df_final_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac8a1d16",
      "metadata": {
        "id": "ac8a1d16"
      },
      "source": [
        "f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b68cb2a",
      "metadata": {
        "id": "9b68cb2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
        "print('Test f1 score',f1_score(y_test,y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c44ad9",
      "metadata": {
        "id": "c5c44ad9"
      },
      "source": [
        "Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39fe4d78",
      "metadata": {
        "id": "39fe4d78"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(test_y, predict_y):\n",
        "    C = confusion_matrix(test_y, predict_y)\n",
        "    \n",
        "    A =(((C.T)/(C.sum(axis=1))).T)\n",
        "    \n",
        "    B =(C/C.sum(axis=0))\n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    labels = [0,1]\n",
        "    # representing A in heatmap format\n",
        "    cmap=sns.light_palette(\"blue\")\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Precision matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    # representing B in heatmap format\n",
        "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Recall matrix\")\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd10ce0",
      "metadata": {
        "id": "cdd10ce0"
      },
      "outputs": [],
      "source": [
        "print('Train confusion_matrix')\n",
        "plot_confusion_matrix(y_train,y_train_pred)\n",
        "print('Test confusion_matrix')\n",
        "plot_confusion_matrix(y_test,y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbcb97ea",
      "metadata": {
        "id": "bbcb97ea"
      },
      "source": [
        "roc auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac3047d",
      "metadata": {
        "id": "bac3047d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr,tpr,ths = roc_curve(y_test,y_test_pred)\n",
        "auc_sc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='navy',label='ROC curve (area = %0.2f)' % auc_sc)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic with test data')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec491173",
      "metadata": {
        "id": "ec491173"
      },
      "source": [
        "feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee5d0ea",
      "metadata": {
        "id": "bee5d0ea"
      },
      "outputs": [],
      "source": [
        "features = df_final_train.columns\n",
        "importances = clf.feature_importances_\n",
        "indices = (np.argsort(importances))[-25:]\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa8993a",
      "metadata": {
        "id": "3fa8993a"
      },
      "outputs": [],
      "source": [
        "#y_test('source','dest')ytestpred()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a93a595",
      "metadata": {
        "id": "4a93a595"
      },
      "source": [
        "# Model: XGBoost Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e32bfb",
      "metadata": {
        "id": "c5e32bfb"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "\n",
        "tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300, 400, 500], 'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\n",
        "model = RandomizedSearchCV(XGBClassifier(), tuned_params, n_iter=15, scoring = 'roc_auc', n_jobs=-1)\n",
        "model.fit(df_final_train,y_train) # actual data and actual prediction\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362352d5",
      "metadata": {
        "id": "362352d5"
      },
      "outputs": [],
      "source": [
        "model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b5ae1d",
      "metadata": {
        "id": "24b5ae1d"
      },
      "source": [
        "* In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff9f8c5",
      "metadata": {
        "id": "cff9f8c5"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "# tuned_params = {'max_depth': [4], 'learning_rate': [0.05], 'n_estimators': [500], 'reg_lambda': [1.0]}\n",
        "\n",
        "clf = GridSearchCV(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
        "       max_depth=4, min_child_weight=1, missing=None, n_estimators=500,\n",
        "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
        "       reg_alpha=0, reg_lambda=1.0, scale_pos_weight=1, seed=None,\n",
        "       silent=True, subsample=1), tuned_params, scoring = 'roc_auc', n_jobs=-1)\n",
        "\n",
        "clf.fit(df_final_train,y_train) # actual data and actual prediction\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d56bff",
      "metadata": {
        "id": "31d56bff"
      },
      "source": [
        "test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19d7cec",
      "metadata": {
        "id": "d19d7cec"
      },
      "outputs": [],
      "source": [
        "y_train_pred = clf.predict(df_final_train)\n",
        "y_test_pred = clf.predict(df_final_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e5046d4",
      "metadata": {
        "id": "3e5046d4"
      },
      "source": [
        "f1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9da236dc",
      "metadata": {
        "id": "9da236dc"
      },
      "source": [
        "F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6310eec",
      "metadata": {
        "id": "e6310eec"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
        "print('Test f1 score',f1_score(y_test,y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d581301",
      "metadata": {
        "id": "3d581301"
      },
      "source": [
        "confusion metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660a6629",
      "metadata": {
        "id": "660a6629"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, y_test_pred).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219efa4b",
      "metadata": {
        "id": "219efa4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(test_y, predict_y):\n",
        "    C = confusion_matrix(test_y, predict_y)\n",
        "    \n",
        "    A =(((C.T)/(C.sum(axis=1))).T)\n",
        "    \n",
        "    B =(C/C.sum(axis=0))\n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    labels = [0,1]\n",
        "    # representing A in heatmap format\n",
        "    cmap=sns.light_palette(\"blue\")\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Precision matrix\")\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    # representing B in heatmap format\n",
        "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('Original Class')\n",
        "    plt.title(\"Recall matrix\")\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0199239",
      "metadata": {
        "id": "f0199239"
      },
      "outputs": [],
      "source": [
        "print('Train confusion_matrix')\n",
        "plot_confusion_matrix(y_train,y_train_pred)\n",
        "print('Test confusion_matrix')\n",
        "plot_confusion_matrix(y_test,y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88aade67",
      "metadata": {
        "id": "88aade67"
      },
      "source": [
        "roc auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faf647e",
      "metadata": {
        "id": "9faf647e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr,tpr,ths = roc_curve(y_test,y_test_pred)\n",
        "auc_sc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='navy',label='ROC curve (area = %0.2f)' % auc_sc)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic with test data')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2aae9e1",
      "metadata": {
        "id": "f2aae9e1"
      },
      "outputs": [],
      "source": [
        "features = df_final_train.columns\n",
        "importances = clf.feature_importances_\n",
        "indices = (np.argsort(importances))[-25:]\n",
        "plt.figure(figsize=(10,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd0595e",
      "metadata": {
        "id": "1fd0595e"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9576900",
      "metadata": {
        "id": "e9576900"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc=accuracy_score(y_test,y_test_pred,normalize=True)*float(100)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537c4919",
      "metadata": {
        "id": "537c4919"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eea97b1",
      "metadata": {
        "id": "1eea97b1"
      },
      "outputs": [],
      "source": [
        "acc=accuracy_score(y_train,y_train_pred,normalize=True)*float(100)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5cf053",
      "metadata": {
        "id": "4d5cf053"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Link Prediction on Facebook Recruiting Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "add3981b",
        "5bf009aa"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}